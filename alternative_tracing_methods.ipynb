{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Tracing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AWTT](../../images/alternative_ways_to_trace_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far in this module, we've taken a look at the traceable decorator, and how we can use it to set up tracing.\n",
    "\n",
    "In this lesson, we're going to look at alternative ways in which we can set up tracing, and when you should think about using these different approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain and LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are using LangChain or LangGraph, all we need to do to set up tracing is to set a few environment variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AWTT](../../images/alternative_ways_to_trace_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set them inline\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\"  # If you don't set this, traces will go to the Default project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry too much about our graph implementation here, you can learn more about LangGraph through our LangGraph Academy course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALsAAAFNCAIAAADXTomNAAAQAElEQVR4nOydB0AUxxrHZ6/ROUCqoAKiqFgw1qixYUkssZfYW+wmFmI0sZtEo4nPxBJj7KjBGHvXgMae2HtDRayggPTj4G7fd7dw3MHswhlJFu77xcfbm7a73/535pvZ2R0Zy7IEQYqMjCCIOaBiEPNAxSDmgYpBzAMVg5gHKgYxj5KqmJio1Hvn0hLj1Kp0LWGJRsMyEobV5o0USBhGF8HqN2AEgdFvaFmplIHEkIBhGG5kgWEI/L9Eoovl8kIUpIfSuDKNoyQQrovSJ4MtKeF2CmlY1mSkQiIlWo3JMcsVjFTO2DhIyvrZ1m3lQkomTMkaj7lzMfnsvviURN2lkMkZhTUjlUkkMobNIoyEZbWMLhHD6q6qRC8EODkIY/WXFySiJYyUYTnFSHIuPJEQAuF6cehz6v7Tweam0SfIIbccAJKD/nLUI9HtNS+ZTkNEqzU5eJkVhLBqlVadoc3OJgobxtvfuv1Qb1KiKDGKuX8lJSI8NktNnNxkNZs61WjkREoyGrUmYmtczK30zAzW08+q29hypIRQMhSz+dvohBfZvtVtOwwtS0oXT+6lHdkUl5mubd3PvWJNByJ6SoBilk2KsldKBs7wJ6WXC5Hxfx1I9Ktu+8FAsd8SYlfMis/vV6ptH9Lbg1gAK6ZENe3iWq2BqBtcUStm+WdRNZs4NunkTiyGn6dG+VS0aT9MvO6whIgVsF1gHXuLkgswYl7A4yjV2QMviVgRqWK2Lo6xtpWG9PYklkf3T8teOJJExIoYFRP3JCP2kXrgdD9ikbh62bhXsFo35yERJWJUzJ6Vz8tWtCYWTI9Py6W+1jy+k0rEh+gUE/8iIyNF23WsD7Fs3H0Ukb+J0ZsRnWIifn1p7yxef/xfo2Uvt9REDREf4qtjnqv9a9iTf5cpU6bs2rWLmMn9+/c7dOhAigdXbxt4anZ8ZxwRGaJTjCaLNO3yb/eob968ScznzXIVHTul7PHdDCIyxDWCd+V44qk98aMXBpDi4dSpUxs2bLhx44arq2utWrXGjRsHG3Xr1uVi7e3tjx07lpqaunHjxjNnzkAVArHNmjUbNWqUtbXOEw8JCRk2bFhkZOSlS5f69+8fFhbGZZwwYULfvn3J2+bA+mdP7mV8/FVFIibEVcfExajkcoYUD7dv3/7000/r1av3+++/T548+e7du7NmzSJ6GcHf6dOng1xgIzw8fN26dSCIxYsXQ/ojR46sXLmSK0Eul+/YsSMwMHDZsmVjxowZMGCAp6fn+fPni0MugHs5K6hxxYa4ZlSlp2mlxaaYy5cvQ1UxZMgQiUQCV7patWpRUVEFk/Xr1w/qEj+/nNGgK1eunD59+pNPPiH6mVZKpTI0NJT8Kzi5KLjJX6JCXIqR6GYzFZdigoODVSrV+PHjGzRo0LRp03LlyhnaI2OgIoEmaebMmVAJZWdnQ4iLS958OdAZ+deQFpst/gHiapUUtkSj1pLioUqVKj/++KObm9uSJUu6dOkyevRoqD8KJoNYaIYgwc6dO6HFGTx4sHGsQqEg/xbJ8ZkilIy4FOPsqcguzpa7UaNG4K/s2bMHPJikpCSob7haxAD0A7Zt29arVy9QDLRcEJKSkkL+I14+U0ukRGyISzFBDR002cXVcl+4cAE8EtiAagbGUSZNmgRqeP78uXGarKysjIwMd/ec7r1arT5+/Dj5j4h/kmlrLzrJiEsxdg5WjIT8fegVKQagDYIu0vbt2xMTE69fvw59IpCOl5eXlZUVSOTs2bPQBoFT7Ovru3v37idPnrx+/XrOnDng/SQnJ6elpRUssHz58q9evYIe1qNHj0gxkJyY7eknuudrohvBc/GQ3btULE/goBMEbc13333XunXr4cOH29nZgb8ik+l8f+hAnTt3DmodqGC++eYb6FJ17969c+fO9evXHzt2LPxs1arVs2fP8hXYpEkT0BN0nQ4dOkTeNtA+ZqlI675eRGSIbg5e1OWUg+tjx/6vuAbxSgrblz559TRz+DxxDd8REdYxAcEOMjmzf+0zYtk8f6Cq19aZiA8xvhPZuLPzn1sT+GLBOYVmhRoFjiqMpjC0Lqm/v/+aNWtI8bBODzUKnjzAYwdq1DvvvLNo0SJq1J5fnkjlpHZzMb43KdKZ4RvmPrSyk/SaWIEay9fjzczMBDeWGgUygotHigfYL4iVGgXhfEM4UqnU1taWGrV0QlTfqd7O7jZEfIj3XYLloVHNu7tVa6gkFsYv0+57+Vl3EOvbteKduzR8vu/RreKdUl9MrPvqvq29RLRyISJ/X0mdoVn55cMuo728A+yIBbBm5n2fSnZt+on6DQqxvxOpUmlWTX1YoZptx49L2xvXxmSkZ278+rGdo6zP575E3JSMN/VXTX+QrWabfFimeuOS/UkHKtt+fPziUWZgHftWfUrA+1kl5msgf2x+cfdiqlTG+NewFeFI6Btw73LShYikhGdqO6V04IwS83JWCfvi0KGw59E307MyWYmEQB1uq2Rs7KRya4UmO2+OhP5LQzlDMtwHqrivUHF/c9LovyqkLXDq3OeojFPqC9F9rso4Wc5nrRhdqVxK08JZ3T5NC9EXrvvcUEaqJjUpS53Bslri5CZv0cvNy5fexxYnJUwxHKoM1Zm9SbGPMlOT1FoNYbUSrdFcNdOLl3eCptu671aRAqculRKNRpdSo9EyTM5YoHHG3HK5717p/jP+NJpxbEHFyBUMIyVyK8bZTe5f0z6oYYlsYUukYv4Fhg4dOm7cOHjQSBBT8FubdLKzs7nH2kg+0Ch0UDF8oFHooGL4QKPQgSfk8BicIAVAxdDBOoYPNAodVAwfaBQ6qBg+0Ch00I/hAxVDB+sYPtAodFAxfKBR6KBi+ECjUNDql7mRSPBzfBRQMRTQ7RUAFUMBmyQB0C4UUDECoF0ooGIEQLtQQD9GAFQMBaxjBEC7UEDFCIB2oYCKEQDtQgEVIwDahQIqRgC0CwVUjABoFzpubm4EoYGKoQDPIGNjYwlCAxVDAZqkfN8SRwygYiigYgRAxVBAxQiAiqGAihEAFUMBFSMAKoYCKkYAVAwFVIwAqBgKqBgBUDEUUDECoGIooGIEQMVQQMUIgC9xUeDebePec0PygYqhg9UMH6gYOqgYPtCPoYOK4QMVQwcVwwd+M9yE4OBgwycduMUFwP/t1q3b9OnTCaIH/RgTAgMDJblIpVL4W6FChf79+xMkF1SMCX369LGxMVnPs169er6+vgTJBRVjQqdOnfz9/Q0/PTw8evbsSRAjUDH5Ma5matasWblyZYIYgYrJT9u2bStVqgQbrq6uoB6CmFJ4Xynmbtq9iymZqtwMuQtN5W3ol58quJQZyV1OzTgLITnbUgnRaPOXSfRrYukW2SoQbrTN6ldao+SVMDnLshVctI3kW4rNNE63sJbR8lzx8fFXr152cnapHVxbn5YluWu15ZWmP86iYLymXMEDk0pYjTb/AnGE5F8RrmB43qETSrjxjozPruA6YRxyKbFzkTZqX/hbWoUoZvWMqMx0IreSZGXm7lJveJON3PPVHVxuoOFkjAONz9nY4sa5JFLdNm0pvdxtRr82X+6ibdw6fbnlEFabt2FyMEZ6IgWVnXtVjNCv0WY4QAnRmq4RCMdpvHBcPnLKL7CYG3dIpophNKYlw8GD5fJOynC/SfTm1ObfkS6UIfnDc3bELUCYd3a6QljKNZfJdYEwAlWljl3IR0LLcAqN4P08Ncq1rKzNAF+CWAYvYpKPhMU5usbXa12GLw1vHfPLl1E+laybdPEhiIWx+duo6o2UjTvQWyi653tmbxw0GSgXy8Q3yO766SS+WLpiYu6prB3wkZOFEvSek0bNG0tXTFa6luB0IktFqbSBFkadQe8K0isS6PeyWoYgloqucwXjHDSw6UFo6MegqKBiEBoFhqcMoGIQGgyDikHMg6/nQ+8rwVgy+r2WDMMSPgHQFaN7skMQy0X3oIonClslhALUMXzzYPgVg7WMBSNw8emKYRiGoCNjyUjM9HxZfCfF0jFzPEY/74YgFgxvE8PfV/qPFNOpS8iGsFXkv+PosSMtQuq+fp1ILBu+6/8fzAx/+PB+7z4d+GJ79exfs0ZtgpjJjp2/zft2JnlLCIzH/Ae96zt3bwrE9vloEEHM586dm+TtITAe89bqGGhNtm379dMJH0OVnpySDCEHD+0ZPXbQB+2bwN/ft23m2rm161Z8u2B2bOwLSLb1900PHkTBxtmzJ7v3fH/Y8I+Iaat048bVyZ+P/bBTi/4Duy7/6X9paWkQeO78Wchy/foVw65v3b6hK+SvU3xZCmXFzz907d6mX//OcHj5XtA/derP4SP6tv2gUc/e7b6YNgGOnAvXaDThWzbA2cG/SaGjrl27zIXDTwg3ZF+wcM6Ikf247c5dW+3ctXXpsu/haLt0aw1R6enp02ZMgp8DBnU7fHifIRfVdMDsOVPmzJ16+vTxDzu3bN22IVj71q3rED5+4vBDh/dCCVDU3Xu3IT3k+nh4n/fbNYa9/7JqKRwtMQezx3zfALlcvnf/joCAwIULltna2P4RcRCUUblSlc0bdw8bOgZOYOny7yHZ4EEje/ca4OHheTTifI/ufbklXzdsXAWN0aSJ04wLfPL0cejk0apM1dIla+fO/u7Bg3sTJg6Hy/lO7XoO9g7HT0QaUp48eRRC6tVtyJdF+Mh37f591+6tn37y+fLlG7y8vDeE/WKIOn/hrxmzPmvTpv1v4ftnTp8fG/t88Y/zuaiVvyzZtWvrnNnfTfviazc3j8+njouJiSaFmSh8y/ry5X0PHTgNNjlwcDccXkjL948cOtuieeuF389NSU2BZHymI/ovTty4efXIH/tX/BR2YN9JK4UV1xItXrSyatXqcJxgVci4fXv4xk1runfrE755b8eO3fbt32ks4qLA8o+t0BUjkZj9YAmGcBwdlePGhNat0wBObP/+nTVr1h7/6RRnZxe4xoMHjty587fExISCueAvXGxQT9UqQcZRf/xxQC6Tw4UHE/v6+odOmn4v6s7JU8ekUmmLFm2On4gwpAT1hIS8D+F8WYSPfPuO8GZNWzVrGuLo4Ph+245wtIaoNWt/avpeSzC9UukUFFRz9KiJUB3evnMzKTnpt60be/ceCEfeuHGz0EnT6tZpGJ/wihRGpYAqH3bsplAomjdrDT+hTNAKmKtF8zag7JhHDyFQ2HQZ6emfhc4o6+UNuUBtjx8/gooq316uXL0YGFitbdsOTk7OHdp3WbZ0XYP6jYk5MMTMOkarfZMHS4GVqxmyX79xpV7ddw1RtWvXg8Cr1y5RM1auVLVg4I0bV6pUCYJLxf309PQqW9aHK6F589bQOkD1S/R+9JMnMWA74Sx8QAX+9OljkFfewVTOOxiopaoY6Zg7wdu3b0Q/vA8bhii4eHNmL6wdXJcUBkiZ27Czs4O/vr4VuZ82NrbwNyUluVDTlSvva2try23b2ztwufLtwPNvzgAAEABJREFUpXr1Whcu/AWtHrRuIG7vsj4BAea9C8zyP7ume766F7rMVwzcOtyGWq3OyspavWY5/DNOULCOycloZVUwMDU1Be5maJhNSkiIh7/BterA/Xf8eATUwCdOHnVzcwcbCWfhAxwdaOO5C8ZhbW2TewCpmZmZVlbWhijuUqWnp6Xqmw9ro6gikm/aieFbNQYKNV3BLAWBStHW1u7U6T+hdQM1ww024uNPXF3fzqp0dMVotf/osZK1tTUYt03r9k2bhhiHl/Uy43UWlzKuNWoEg99jHKh01NUfYHdomKC5gWYenJjWrdoVmoUPuNehOcs0vCQM1X5GuuEs4K9KlWGISkvX+dFlXFzt7OyJXjqkMDRa81zOt2I6UBU0RvAvOvrBxYt/r9uwMi0t9Zuv/lf0Ev6DOXgVK1YGP85QUcN98/z5U3d3DzNK8K90+Mi+WjXfMdxVcP4+PuW57ZbN24B/B14FeCpfTJ1blCxUQHweHl7QwyI9ckLO/nWS24C7M7ByVV1ULty2f8VKXp46NwLcBfA3ib5pm/rl+BbNWoProFBYGTQHgJ9BzOSfm+7Qob3Qtvr5VYTWFv5Bafv27yBmwZg55vvP+Xjo2FOnju0/sAvaYOh5Qp9wYuhIqHIhCi5hfPyrkyePCVuze/e+kBe6CSqVClL+vPLHIcN6PXgYxcWCzwhGhM6wv3+AwQsRzsIH+J7gO8NQL2z/Gr7+5s1rhqgunXtBTQajBjBecOny+eU/LQJXtFJAoL29PVRs0FeC/g6EL1m6EPwGTj3VqtX483gEtGiwHbZx9atXceTtmU4Ab+9y0NO+eOkctF8RkQehiwedcHBi4KY6cTKyelAtYib/9pgvtA4rV2y6evUSDDxAjxdqxa/mLrLS+ysNGzSpUT14+szQiMhDAiVAz2X1qi021jYjRvWD4YrLVy58FjodHBdDAuhugPPbskXbomeh0q/v0PbtOsNVBwfozNkT0CEi+moD/kJ/deiQ0Vu2hnXq3PLbBbNgMHrG9HlcLuiNBwfX/X7R1xMnjdRd11kLOa927JhQF+cyHTs1h/ESaOw4l/xtmU6Aju27Qn352eQx9x/cg3EK3wr+X06f2LlLCHTaGzdqNnHCl8Qs+Fsl+nvX6+dGs1qm2/gKBLFI1s2KGvFtQG5PxgScg4eYB1/vmtH+g76S2Oj4YXO+qM8/n9WkcXOC5Ic1b9amVluqplStXLmZL8rZyYUgFN7kncjSM23Ty7MsQczEPMXg20oIHzgzHKFj3piv3o9ByVg0+IYbYh74pj5iHubVMTAeg62SJcO8kR9DEIuFRT8GeVugYhDzoCtGYSNls82bPIaUJiQSopDyRFFDbeyISoWKsVAeR+lmMROzFNOip2tGKrq+FsrVo68dy/C6K3TFKMvYePopNs0rZL4jUvq4fDI2MTaz/xe+fAmE1lc6e+jlpYgkL39b70o2NrYKUiRYhudBufF6RdxiUUZHQe/MGa9lRQorkz8RS32ymrv8ESv4CI13DyzJWTvJXEzO1fTEGf2hstTEAmdBs57xmkomluc5X4k0+9XTzOibaenJmpHfBhCB4xceeDl78OWts6mZ6ZrsLFJCYVmRPYovkswLZOI7C77SeML5kkuljFRBlG6yXhMKmaqLK6TTGTp06Lhx44KDgwliCo7H0MnOzpbJ0DgU0Ch0UDF8oFHooGL4QKPQQcXwgUahg4rhA41CBxXDBxqFDiqGDzQKnaysLO4bfUg+UDF0sI7hA41CBxXDBxqFDiqGDzQKBXjWptVqpTwLPls4qBgK6PYKgIqhgE2SAGgXCqgYAdAuFFAxAqBdKKAfIwAqhgLWMQKgXSigYgRAu1BAxQiAdqGAihEA7UIBPV8BUDEUsI4RAO1CAZ4rVaiAazLQQcVQkEgk0dHRBKGBiqEATVKhK9haLKgYCqgYAVAxFFAxAqBiKKBiBEDFUEDFCICKoYCKEQAVQwEVIwAqhgIqRgBUDAVUjACoGAqoGAFQMRRQMQJICFIAqVSqxeVfeEDF0MFqhg9UDB1UDB/ox9BBxfCBiqGDiuEDvxluQnBwMLi9DMNwnq9EIoGNpk2b/vDDDwTRg36MCX5+foz++/+gFU467u7uw4YNI0guqBgT2rVrB1oxDgkMDKxRowZBckHFmDBw4EAfHx/DT6VS2a9fP4IYgYoxQaFQ9OjRw/B1Kn9///r16xPECFRMfj766CMvLy/YsLW17d+/P0FMKWrv+kVMamoCy+jbeAnLahnD+mCMhOi7W0YrieVtmgTmLMimX10sd1kooyXfqCu26ZIyhmXMGAnD8iwQByUa9qRfqMwIniXi9HvOy5aXrEe7cTt37fRwd/NxqnP/alpuYqPDph6w6apZ3AJx+RbAMj4dw+5MDp5nX3znxV0MUkR4FtiTMtm+NZSkaBTeu44If3H/SmqWWnd8Wi2XibpwnVForqEkEuimCpbPMKTgARRhlTPBdQP5FFKwYIZ/7fjCE+v0a3R2lGXWChTBc2YFDoN6XNTV/fQ6KkpKfTjN2qAYGYHzsFcyA6dXJIVRiGKunUo4sSMhuIVzjSZlCFJ6SU3NOLbleVKcduT8AOGUQoo58uuzh1fTP5pSSBFIqeHsgRdRl1JHCa4sKuT53r+c/k4rF4JYDA0/8FQoJPvXPRNIw+v53r2WCF5LYF1UjGXh5Cl/EZ0hkIC3jkmPF14IGimd2DhYZauFrjtvHaPRSrXZ+JDS4mCzSLZaK5AAZzsg5sGrGF3PHRslC0SiG2cSiBeqY1AwlomwLyLjz8YQdGMsD6awZ438rRKDlYwlwmqJ8IMd/laJ8lgQsQwEr7tgqyTUyUJKKRKWYd7U80UsEa3JA/mCoGIQUyTsG7ZK6MNYJoy2kEsvNIKHqrFEoG/9ZiN4WhyPsUhY8GM0Qheed7Sm1NQxDx/e792nA0HeEqV/zPfO3ZsEMYs383zfAK1W+8OP3548dUwhV4SEvF89qNbUL8dv23rIxUU3R/jgoT2792x7+DDKzy+gZYs23bp+xPX7O3dtNXjQyKSk1+s3rLSxsalX992xY0LLlHEl+lVrVq9Zfvavk3FxL6pXD+7SqWfDhk24fXXqEjKg37DjJyOvXr20a2ekhJFs/X3j3+fOREffL+Pi2qhRsyGDR1lbW69dt2JD2CpI3yKk7uhRE3p073vjxlXY0e3bN5ROzu82fG/ggOF2dnbC57Vte/jmX9dOGD915qzJnTv3HDcmNCEhfvlPi67fuKJSqerVexeOpFy5CkS/aMq27b8eOrT38ZNHFcr71a3bEA5DKpX+tnXj5l/XhU6ctmjxN69fJ5Yt6wNZ2rRpz5UfExO9+If5d+/dkkplvr7+gwaOqB1cF8J37PwtbOOqxYtWzpw9OTr6gb9/ABz/+207QlRKagqc2l9nTya+TgisXK1Vqw/at+vMlcZn5yIikYIbI5Sev1ViCk6NL4Stv2/as3f7uLGfrVix0cbGFi420b/ADH//iDj47YLZlStV2bxx97ChY37ftnnp8u+5XHK5fMuWDZBs546I9Wu3Xbt+ed36n7moH5csgJRdOvfavGlPs6YhYLg/j0cYcu3dvyMgIHDhgmW2Nrbbd8BFXderZ/9vvl48YsSnx/48ArKAZKDF3r0GeHh4Ho04D+Z+8vRx6OTRqkzV0iVr587+7sGDexMmDi/0Gw4KhSI9PW337t+nTpkDqtVoNBMmjbh85cKE8V+sWbXF2cll9JiBT589gZTbt4dv3LSme7c+4Zv3duzYbd/+neFbNhDdR69kaWmpEZEHN4XtgtMMadl2/oJZjx8/gqjExISx4wa7u3uu/HnzsiVrobS5X32Rnp7OnWNqagoY4bNJ0yP/ONesaasFC+fExr6AqAULZt+8cXX8+Knr1vxetWr1/y2eB3eCsJ2LiFZbSNPCqxjdXAczP/tw6PDepu+1bN6sldJR2bfPYFuje3f//p01a9Ye/+kUZ2eXd2rXGzxw5M6dv4GxuFhv73L9+g5xsHeAqgXqmLt3b0FgZmYmFNjno0EfduwGBbb7oFNIy/c3hP3CZYH7xtFRCbd73ToNZDJZzx79Vq38FXYNd+d7TVq0aN7m73OnCx7hH38ckMvkoJXy5X3hbg6dNP1e1B2oFIXPC/YFdUnv3gNbhbzv41P+2rXLUCt8MXVug/qNoPocNXK8o9Jp27bNkPLK1YuBgdXatu3g5OTcoX2XZUvXNajfmCsEdNm1S2+oRB0dHKEWsbO1i4g8RPS3mcLKKnTStLJe3lD4Z6EzMjLSd+3eyuXKysqCWrBatRpwDG3bdIA6LCrqDrejpk1D6tVt6O7uMfzjcbCjMmXcCrVzkWCJ8Age/3NKM59EQpMENWdQUE1DSNP3QgxRUIGDFAxRtWvXg8Cr1y5xPytXrmqIcnBwhNsRNkA3arXaOFdwrToPHkQlJSdxP6E2NkTB7Xju/JlRowe0btsQGiBoBahmunHjSpUqQUqlE/fT09MLGgjDYQhTJTCI24BaEHYH14P7CdcSDgwuIWxXr17rwoW/oCaApgGO07usT0BAZUMJhtOELLDfmJiHsP3gYVSlSlUMS8ZBE1nOpwJ3z+Tst0qQwTJE95pICvytUSMYzvGnFYtPnz4OqgqsXBXOpVA7F4nC2haBJ5HELM8X7kK4A2xt8+oVw4WBCw9nBY0U104ZMFxUakPLmWbcp0PzhScmxEOVQ/SNhSFw5S9L4PaC9gjsBW3QqtXL9h/YRS3z9p2bIKl8BZIiYNgdFAKnk68QqFTgL7RHYIFTp/+EpgFE0Lx56xEff+Lq6salsbKyMqS3srbmboyE+FdQxRoXZW1jk56RbvhJNc7nk2dBKxl59BDoxt7OvkuXXgP6fwzVmLCdi0Rhbctb83w5g8IRG0ISE3OuBHigtra2bVq3h4rUOEtZLx+BAsvoDT1p4pf5DApNfr6UoNQ9e7fB1YKGgAvh1FYQlzKucHeCc2McqHR0IuYATSc0Ll9/9T/jQKlE93I/eGNwDPAPqtuLF/9et2ElyOKb3JRpaWkGLztTpQKXBTag7Qa/yriojPR0H+/ywscATRu049D0X79+5cTJo2EbV9vbO0DT/AZ2zgcDnq9UaIYMr2KkjFZ49l7+gmQyaFOhq2IIgVvNsF2xYmVw77kuANEL6/nzp5BeoECwGndTGnLBvaKvxmzzpYTSMjIyXF3duZ9QpZ0+c5xaZkX/SoeP7KtV8x3DR2Lg0oL3QMwBzgV2B8KFRocLefb8qZNSV8dALwmaHj+/iuAkwT845X37dxgyXrp8rknj5kTvosU8jn733feIvm0Fd82w+m1ySvKjmIeGbhQVaO8iIg6CYwe3ItwA8A+cm7v3bpM3snM+WC0Rfk2WV00aViLsARWk0btN4XqcO38WdgkOXUpKsiHq46FjT506Bi0FNKvgOc6ZO3Vi6Ei4tAKlgTLAQwRXF9JDSuglQTcHeqEFU0L1Bp7sgeybNhMAAAygSURBVIO7ocMCvfQF382pUT0Y9g73NMSCIOLjX508eQz6Jt2794UDgO4DtKHw8+eVPw4Z1gs8CWIOdd6pX79+o+++mwvdFtjdzl1bR47qf/DgboiC3tCMWZ+BbwEX9ezZkydORsIQA5cLNAo9KXCZoau1Zu1PIBpw5CEculRQD32/6GsoDeQ7b/4Mayvrdh90FjgAmVQGPcFZcz6HCgb6+YcP77sXdRtO+c3snJ/CPF+BOXhmj/mCVw932+TPx8LNFxxcF5oJ8AFlMt2tA/fByhWbNm1eCxdJpcoIqlbzq7mLjNt1KtAxhptmc/g6qOHt7Owh16RJ06gpp3/5zbLl3w8a3B1uu9GjJsLe//77dJdurdav29awQROw5vSZoXB4gwYOX71qS3j4+hGj+sHFA6fys9Dp0BclZjLv68Uw5jHnq6k3b16DkRgYDunatTfRtaHTli777svpE2EbulHQPPXonvPBInBHoNWA6wfyhUZtyuRZ3BCOj3e5mTPmh4WtgoFp8Pygq/zD4lXCQ0QQO2fWwiXLFnJOHlRpI0eM/+D9D9/YzmbB+971hciks3teDphlxkvXcOPCUBvc7txPGIrYtGnNnt3HiMUDY4Aw4hdx5G8iek5si3t0O2XUAt6PPPC2ShLdWwjELEAiw0f2BetAXR159DC48R9+2J0gJQrdt0XerK+kG/szc9Ym1PlJSYmHD+/9ZdUSNzcPGKsFZ56UBOBpxvVrl6lR7dp1hjE6YkEwbCHRPIK6GPn6zL74ATMK/wRNKQB8C3UW3T2ERxCGgSVL4Pj22JhbqQKtkvDMcEuZIMM9+ER0/KN5vjgHDymA4DxfnINngTDkTd8+wXciLRO2kDFfwXciEaQAgu9dI0gBBN8lQCwPRsJK3+zZtS4TtkuWB6tlNJo3+qoZy6Lni1AQGMHDOgahINAqaST4Gr8FIsmWyoXieUWhdBfMh5RSVKlahbVUIAGvV+xf3UEiIddOvyKIJRH/QlXWXyGQQKgfFdTI/tqfrwliMRwJ171017a/t0CaQlbLeXQ7bd/q5xWD7eu2cTF+2wMpZTy5m/L34VcaNTtktr9wysJX5Dp35NXlY0mZGfrO03/Ue2L+Sb/tnwwTvHHe/2KnLPuGI/VSqS6rk7us72TfQhObsUJ63FM1U6QFyIyiTN6WMloMkPYWFd+6ZbmzwlieYnmzcyEMq/uPLy9frvnz5nft2jmwcpWCn7gwLiH/keT+zinWKNp4sTWepdR0aQwXxPjATIqhLKhI8u2CmjdvrT1DSO6GQkqUHkVtQMzoQLt7W1CrFJ/ywNGVcbWkUy4iOORCJzs72/AuNGIMGoUOKoYPNAodVAwfaBQ6qBg+0Ch0QDHcq/NIPlAxdLCO4QONQgcVwwcahQ4qhg80Cp2srCxUDBU0Ch2sY/hAo9DRaDSoGCpoFApYwQiAdqGATowAaBcKWMcIgHahgIoRAO1CARUjANqFguF7zEhBUDEUsI4RAO1CARUjANqFAipGALQLBfRjBEDFUMA6RgC0CwWWZf38/AhCAxVDJzo6miA0UDEUoEkqdIFaiwUVQwEVIwAqhgIqRgBUDAVUjACoGAqoGAFQMRRQMQKgYiigYgRAxVBAxQiAiqGAihEAFUMBFSMAKoYCKkYAVAwFUIxGoyEIDTMXQbcYpFIpVjNUUDF0sGHiAxVDRy6XZ2VlEaQA6MfQwTqGDzO+GW4JtG3blvNgEhISrKyswP9Vq9VBQUFhYWEE0YN1jAkMw8TFxXHbmZmZ8NfZ2XnEiBEEyQX9GBOaNWuWr9ItX758kyZNCJILKsaEIUOGeHl5GX7a2dn16dOHIEagYkzw8PBo3bq14SdUMMY/EYKKKcigQYPKlSsHGwqFomfPngQxBRWTH6VS+cEHH0CPCSqYjh07EsSUEty7Prv/5cMb6ckJ2ZpsltXolpvSrUTGEpbJXc6MzV10islbGI3Rb7Da3JuFtmBa3opWxrH6MnNX+dLvxYBpIQUX3GL0/5PJGWtbSRkvRcP2Lm7eNqRkUiIVs3Heo9dxWXANFNZSa0crG2drG3sF1Ar5rj2jJVqJbg03/TpuudeY+5mnCSZniTjjlc/yFFBgpTQ2d6W0vH3pBcIUSGOMls3MVKuS1Gmv1ep0tTZbq7BiqtRzeK+LOylplDDFbF0cExujlltJPQNdlB72pMQSczUu9VU6iLxNf3e/IAdScigxioHh15VTohkp4/+uV6lZFffpzZevn6WW9bfuMsaHlBBKhmKS4tVhX8e4lHMoW8WVlDrunHhkbc0MnFEyvg1QAhSTEKvePD+mepvS/LGFW8ei3bytun9SAmoasSsm7XXm2tmPS7dcOO6eeiSXs4NnViTiRuzjMevmPvas5EQsgMqNK6Qns/vXPSPiRtSKCfsm2spO7urnTCyDoFZ+D66kq1PVRMSIVzHRt1KT47MD3i0xnYi3go2zVdiCJ0TEiFcxkeEvYXSOWBgV65XNSNPG3E0lYkWkislIUWWkaCrWL0vEysIlH23bs4AUA1a28mO/vSJiRaSKObw5Xiq30Kekbv6O8LCMiBWRXpXY6ExrpcU1SRxOno7w9/rp10SUiHSeb1am1q2SLSkeNJrsA3+suHX31OvXL/wq1GrUoEe1wMYQ/jz2/vdL+3wyYk3k8fXXb/2pdHQPrtG6XesxumechLyIexC+bU7sy4cB/nVaNRtCihNGQu5dTKneSIzDCmKsY9KTs2BY0dnLkRQPO/Z+d+LMr00a9Phi0s4aQS03hE+5ej0SwmVS3XfCt+6aV7tm2/kzT/bpPvvPU5uu3PiD6L4JnbVqw3gnpfvkT7a0bzP22MmNKSnF6GoobOWpySJ9jVeMinn6IIMUG1lZmecv72v53sB363e1s1U2qPMh6OPIsdWGBLWCWtaqHiKTySv6vVPG2fvJ09sQeO3m0ddJsR9+MMHZydPT3b9Lh9AMVQopNqQyaUaqlogSMSpGlV6Mxnr87FZ2trpyQANDSEXfd57HRqWlJ3E/fcpWNURZWztwyngV/1ght3Zxzpk07ujg6qT0IMWGVCphRSoYUfoxCoV+rlvxoMrQDXUsWzU8X3hKarxUorMGw1DuovSMZIWViV8ll1mTYoPVshKJSJ/3iVExTl6K4ns86uiomy/RvdNUV5dyxuHOSs9kftfE1sYxMzPdOESVmUaKDY1Go7AWaTdWjIrx8LYhDMl4nWHj9PYnw7qVKS+X6/rt0OXhQlJSE+ABvhVUIfyeibOTV1aWChovL48A+Pn0+d3klJek2MjOzHb0FOlyPSIVstyKSXheLDcxKKNNi4+PHF394NHlrGw19JJWrhu3fW8ho7dBVZvKZIqtO+ep1aqk5Jcbf5tma6skxYYmm/WuKNKp4yIdj1G6ypPji6vH1OK9/mW9Kh89seHe/XPW1va+5Wr06PSFcBYba/uh/RbtO7x02tctwQWGDvbFq4eKyddSq9XabLZRB5HONhTpjKrb55MjwuOCQixxkaPoi881KvXQuf5ElIi0VapS11EmY57eLEZfQbSkJaiqvivetwvE+zWQwLoOt/5O8a7mxpdg2tch1HCtVgM9ZL4O+pTx2+zt3tro++qwiQ9jrlCjoHsFfXJq1FdfRhAent19KZWRRu14z/o/R9TzfFdOvW/jYluuOv01sITEN5ng6OL8NmdQJCe/ytbQp8xlZmZYWdmYeww3Ix/WaeXcoG0ZIlZErZiURPX6uTHVW1uKNxN15olcwQ6c5ktEjKjnoDg4K6o2sL8ZGU0sgNiohCxVlsjlQsT/LkFIL0/vitbXjzwkpZqnt+JeRSeNWhBARE/JeCfyfETC3wcTqrUsnc3ToyuxKXHpYxeVALmQEvTe9aGw5/cupjl62ZSv4UlKEXdOxMCDxxHzxP5im4GS9G2HhBcZWxY91WQRV19Hz8ri7U0Ukai/nqiSsrz8rbqNK0dKDiXv+zGHNj6PupRGWCK1lig97d38lDJZifnGbFJc6utnKWmJmWw26+Ai7T7e29a+hH2noqR+o+ryn4nwLzVRN++Im9ACg3as8URHCUO0Oadm+tEoFgb3WLbAdu63hVjCSqAorUmgvgit7nduCOxUnyb3Y1i6LCyrj9f9lBLdwcCBaXPK5P4PcimsJe7lFJ1GltQ390rDN8Nvn09Miteo0rWM1ujDUfpLaPjJ6rWh32AZiSRPQQY16S+8Pl6XlwvME5TOThK9NHKFlfMdqpyvVXHF6D+Epf+p15M+ty6RTC6xVTIe/tZe5Ypruvu/Bn5lHjEP/Mo8Yh6oGMQ8UDGIeaBiEPNAxSDmgYpBzOP/AAAA//981vFUAAAABklEQVQDALa5rMTaT0r7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import operator\n",
    "from langchain.schema import Document\n",
    "from langchain_core.messages import HumanMessage, AnyMessage, get_buffer_string\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from utils import get_vector_db_retriever, RAG_PROMPT\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "retriever = get_vector_db_retriever()\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature= 0.7)\n",
    "\n",
    "# Define Graph state\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    messages: Annotated[List[AnyMessage], operator.add]\n",
    "    documents: List[Document]\n",
    "\n",
    "# Define Nodes\n",
    "def retrieve_documents(state: GraphState):\n",
    "    messages = state.get(\"messages\", [])\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(f\"{get_buffer_string(messages)} {question}\")\n",
    "    return {\"documents\": documents}\n",
    "\n",
    "def generate_response(state: GraphState):\n",
    "    question = state[\"question\"]\n",
    "    messages = state[\"messages\"]\n",
    "    documents = state[\"documents\"]\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    \n",
    "    rag_prompt_formatted = RAG_PROMPT.format(context=formatted_docs, conversation=messages, question=question)\n",
    "    generation = llm.invoke([HumanMessage(content=rag_prompt_formatted)])\n",
    "    return {\"documents\": documents, \"messages\": [HumanMessage(question), generation]}\n",
    "\n",
    "# Define Graph\n",
    "graph_builder = StateGraph(GraphState)\n",
    "graph_builder.add_node(\"retrieve_documents\", retrieve_documents)\n",
    "graph_builder.add_node(\"generate_response\", generate_response)\n",
    "graph_builder.add_edge(START, \"retrieve_documents\")\n",
    "graph_builder.add_edge(\"retrieve_documents\", \"generate_response\")\n",
    "graph_builder.add_edge(\"generate_response\", END)\n",
    "\n",
    "simple_rag_graph = graph_builder.compile()\n",
    "display(Image(simple_rag_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're setting up a simple graph in LangGraph. If you want to learn more about LangGraph, I would highly recommend taking a look at our LangGraph Academy course.\n",
    "\n",
    "You can also pass in metadata or other fields through an optional config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"response\": \"Which of the following purchases would you like to be refunded for?\\n\\n  invoice_line_id  track_name                        artist_name    purchase_date          quantity_purchased    price_per_unit\\n-----------------  --------------------------------  -------------  -------------------  --------------------  ----------------\\n              267  How Many More Times               Led Zeppelin   2009-08-06 00:00:00                     1              0.99\\n              268  What Is And What Should Never Be  Led Zeppelin   2009-08-06 00:00:00                     1              0.99\",\n",
      "            \"trajectory\": [\"refund_agent\", \"lookup\"],\n",
      "        },\n",
      "    },\n",
      "    {\n",
      "        \"inputs\": {\n",
      "            \"question\": \"Who recorded Wish You Were Here again? What other albums of there's do you have?\",\n",
      "        },\n",
      "        \"outputs\": {\n",
      "            \"response\": \"Wish You Were Here is an album by Pink Floyd\",\n",
      "            \"trajectory\": [\"question_answering_agent\", \"lookup_album\"],\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"inputs\": {\n",
      "\"response\": 'Which of the following purchases would you like to be refunded for?\\n\\n  invoice_line_id  track_name                        artist_name    purchase_date          quantity_purchased    price_per_unit\\n-----------------  --------------------------------  -------------  -------------------  --------------------  ----------------\\n              267  How Many More Times               Led Zeppelin   2009-08-06 00:00:00                     1              0.99\\n              268  What Is And What Should Never Be  Led Zeppelin   2009-08-06 00:00:00                     1              0.99',\n",
      "            \"trajectory\": [\"refund_agent\", \"lookup\"],\n",
      "        },\n",
      "    },\n",
      "    {\n",
      "        \"inputs\": {\n",
      "            \"question\": \"Who recorded Wish You Were Here again? What other albums of there's do you have?\",\n",
      "        },\n",
      "        \"outputs\": {\n",
      "            \"response\": \"Wish You Were Here is an album by Pink Floyd\",\n",
      "            \"trajectory\": [\"question_answering_agent\", \"lookup_album\"],\n",
      "        },\n",
      "    },\n",
      "    {\n",
      "        \"inputs\": {\n",
      "list(\n",
      "    my_streaming_chat_model(\n",
      "        [\n",
      "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Please greet the user.\"},\n",
      "            {\"role\": \"user\", \"content\": \"polly the parrot\"},\n",
      "        ],\n",
      "    )\n",
      ")\n",
      "\n",
      "If ls_model_name is not present in extra.metadata, other fields might be used from the extra.metadata for estimating token counts. The following fields are used in the order of precedence:\n",
      "metadata.ls_model_name\n",
      "inputs.model\n",
      "inputs.model_name\n",
      "\n",
      "​Provide token and cost information\n",
      "By default, LangSmith uses tiktoken to count tokens, utilizing a best guess at the model’s tokenizer based on the ls_model_name provided. It also calculates costs automatically by using the model pricing table. To learn how LangSmith calculates token-based costs, see this guide.\n",
      "However, many models already include exact token counts as part of the response. If you have this information, you can override the default token calculation in LangSmith in one of two ways:\n",
      "\n",
      "Extract usage within your traced function and set a usage_metadata field on the run’s metadata.\n",
      "Return a usage_metadata field in your traced function outputs.\n",
      "Navigate to Settings.\n",
      "Select the workspace you want to delete.\n",
      "Click Delete in the top-right corner of the screen.\n",
      "\n",
      "Was this page helpful?YesNoSuggest editsCreate an account and API keyManage organizations using the API⌘IAssistantResponses are generated using AI and may contain mistakes.Docs by LangChain home pagegithubxlinkedinyoutubeResourcesChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'how do i enable langsmith tracing in langchain using langsmith?',\n",
       " 'messages': [HumanMessage(content='how do i enable langsmith tracing in langchain using langsmith?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"I don't know.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 1011, 'total_tokens': 1015, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CN060Y7VGaWPWLVZOjfPrA2ia8Cgx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--e5a6e4b2-58f7-44ea-ac81-a1acb357a11f-0', usage_metadata={'input_tokens': 1011, 'output_tokens': 4, 'total_tokens': 1015, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})],\n",
       " 'documents': [Document(metadata={'id': '396bd0c0-6ef8-47ba-aca4-059d48ba8f5b', 'changefreq': 'weekly', 'loc': 'https://docs.smith.langchain.com/evaluation/tutorials/agents', 'priority': '0.5', 'source': 'https://docs.smith.langchain.com/evaluation/tutorials/agents'}, page_content='\"response\": \"Which of the following purchases would you like to be refunded for?\\\\n\\\\n  invoice_line_id  track_name                        artist_name    purchase_date          quantity_purchased    price_per_unit\\\\n-----------------  --------------------------------  -------------  -------------------  --------------------  ----------------\\\\n              267  How Many More Times               Led Zeppelin   2009-08-06 00:00:00                     1              0.99\\\\n              268  What Is And What Should Never Be  Led Zeppelin   2009-08-06 00:00:00                     1              0.99\",\\n            \"trajectory\": [\"refund_agent\", \"lookup\"],\\n        },\\n    },\\n    {\\n        \"inputs\": {\\n            \"question\": \"Who recorded Wish You Were Here again? What other albums of there\\'s do you have?\",\\n        },\\n        \"outputs\": {\\n            \"response\": \"Wish You Were Here is an album by Pink Floyd\",\\n            \"trajectory\": [\"question_answering_agent\", \"lookup_album\"],\\n        }\\n    },\\n    {\\n        \"inputs\": {'),\n",
       "  Document(metadata={'id': 'ae77e446-199a-4976-810b-c011504eeaf9', 'changefreq': 'weekly', 'loc': 'https://docs.smith.langchain.com/evaluation/tutorials/agents', 'priority': '0.5', 'source': 'https://docs.smith.langchain.com/evaluation/tutorials/agents'}, page_content='\"response\": \\'Which of the following purchases would you like to be refunded for?\\\\n\\\\n  invoice_line_id  track_name                        artist_name    purchase_date          quantity_purchased    price_per_unit\\\\n-----------------  --------------------------------  -------------  -------------------  --------------------  ----------------\\\\n              267  How Many More Times               Led Zeppelin   2009-08-06 00:00:00                     1              0.99\\\\n              268  What Is And What Should Never Be  Led Zeppelin   2009-08-06 00:00:00                     1              0.99\\',\\n            \"trajectory\": [\"refund_agent\", \"lookup\"],\\n        },\\n    },\\n    {\\n        \"inputs\": {\\n            \"question\": \"Who recorded Wish You Were Here again? What other albums of there\\'s do you have?\",\\n        },\\n        \"outputs\": {\\n            \"response\": \"Wish You Were Here is an album by Pink Floyd\",\\n            \"trajectory\": [\"question_answering_agent\", \"lookup_album\"],\\n        },\\n    },\\n    {\\n        \"inputs\": {'),\n",
       "  Document(metadata={'id': '44b74131-76ec-4e83-81fc-af541e93a42a', 'changefreq': 'weekly', 'loc': 'https://docs.smith.langchain.com/evaluation/how_to_guides/multi_turn_simulation', 'priority': '0.5', 'source': 'https://docs.smith.langchain.com/evaluation/how_to_guides/multi_turn_simulation'}, page_content='The response looks like this:\\nCopy{\\n  \"trajectory\": [\\n    {\\n      \"role\": \"user\",\\n      \"content\": \"This piece of junk car is a complete disaster! I demand a full refund immediately. How dare you sell me such a worthless vehicle!\",\\n      \"id\": \"chatcmpl-BUpXa07LaM7wXbyaNnng1Gtn5Dsbh\"\\n    },\\n    {\\n      \"role\": \"assistant\",\\n      \"content\": \"I\\'m really sorry to hear about your experience and understand how frustrating this must be. I\\'d like to help resolve this issue as smoothly as possible. Could you please provide some details about the problem with the vehicle? Once I have more information, I\\'ll do my best to assist you with a solution, whether it\\'s a refund or other options. Thank you for your patience.\",\\n      \"refusal\": null,\\n      \"annotations\": [],\\n      \"id\": \"d7520f6a-7cf8-46f8-abe4-7df04f134482\"\\n    },\\n    \"...\",\\n    {\\n      \"role\": \"assistant\",\\n      \"content\": \"I truly understand your frustration and sincerely apologize for the inconvenience you\\'ve experienced.\\\\n\\\\nPlease allow me a moment to review your case, and I will do everything I can to expedite your refund. Your patience is greatly appreciated, and I am committed to resolving this matter to your satisfaction.\",\\n      \"refusal\": null,\\n      \"annotations\": [],\\n      \"id\": \"a0536d4f-9353-4cfa-84df-51c8d29e076d\"\\n    }\\n  ]\\n}'),\n",
       "  Document(metadata={'id': '7cd812cb-5fdf-444e-b03b-adcb14aed554', 'changefreq': 'weekly', 'loc': 'https://docs.smith.langchain.com/evaluation/tutorials/agents', 'priority': '0.5', 'source': 'https://docs.smith.langchain.com/evaluation/tutorials/agents'}, page_content='\"content\": \"I\\'ve refunded you a total of $1.98. How else can I help you today?\",\\n                },\\n                {\"role\": \"user\", \"content\": \"did prince release any albums in 2000?\"},\\n            ],\\n        },\\n        \"outputs\": {\"route\": \"question_answering_agent\"},\\n    },\\n    {\\n        \"inputs\": {\\n            \"messages\": [\\n                {\\n                    \"role\": \"user\",\\n                    \"content\": \"i purchased a cover of Yesterday recently but can\\'t remember who it was by, which versions of it do you have?\",\\n                }\\n            ],\\n        },\\n        \"outputs\": {\"route\": \"question_answering_agent\"},\\n    },\\n]')]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"how do i enable langsmith tracing in langchain using langsmith?\"\n",
    "retriever = get_vector_db_retriever()\n",
    "docs = retriever.invoke(question)\n",
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "simple_rag_graph.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's take a look in LangSmith!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing Context Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, you can use the trace context manager to log traces to LangSmith. This is useful in situations where:\n",
    "\n",
    "You want to log traces for a specific block of code.\n",
    "You want control over the inputs, outputs, and other attributes of the trace.\n",
    "It is not feasible to use a decorator or wrapper.\n",
    "Any or all of the above.\n",
    "The context manager integrates seamlessly with the traceable decorator and wrap_openai wrapper, so you can use them together in the same application.\n",
    "\n",
    "You still need to set your `LANGSMITH_API_KEY` and `LANGSMITH_TRACING`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AWTT](../../images/alternative_ways_to_trace_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable, trace\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "MODEL_PROVIDER = \"openai\"\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "openai_client = OpenAI()\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "\"\"\"\n",
    "retrieve_documents\n",
    "- Returns documents fetched from a vectorstore based on the user's question\n",
    "\"\"\"\n",
    "@traceable\n",
    "def retrieve_documents(question: str):\n",
    "    documents = retriever.invoke(question)\n",
    "    return documents\n",
    "\n",
    "\"\"\"\n",
    "generate_response\n",
    "- Calls `call_openai` to generate a model response after formatting inputs\n",
    "\"\"\"\n",
    "# TODO: Remove traceable, and use with trace()\n",
    "@traceable\n",
    "def generate_response(question: str, documents):\n",
    "    # NOTE: Our documents came in as a list of objects, but we just want to log a string\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "    # TODO: Use with trace()\n",
    "    # with trace(\n",
    "    #     name=\"Generate Response\",\n",
    "    #     run_type=\"chain\", \n",
    "    #     inputs={\"question\": question, \"formatted_docs\": formatted_docs},\n",
    "    #     metadata={\"foo\": \"bar\"},\n",
    "    # ) as ls_trace:\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": RAG_SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    response = call_openai(messages)\n",
    "    # TODO: End your trace and write outputs to LangSmith\n",
    "    # ls_trace.end(outputs={\"output\": response})\n",
    "    return response\n",
    "\n",
    "\"\"\"\n",
    "call_openai\n",
    "- Returns the chat completion output from OpenAI\n",
    "\"\"\"\n",
    "@traceable\n",
    "def call_openai(\n",
    "    messages: List[dict], model: str = MODEL_NAME, temperature: float = 0.\n",
    ") -> str:\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\"\"\"\n",
    "langsmith_rag\n",
    "- Calls `retrieve_documents` to fetch documents\n",
    "- Calls `generate_response` to generate a response based on the fetched documents\n",
    "- Returns the model response\n",
    "\"\"\"\n",
    "@traceable\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To trace with tracing context, you can create a run with a unique ID and establish its place in the hierarchy by using a parent dotted order. When constructing a run, include the parent dotted order to link it to its parent run, which allows for organized tracing of operations. This way, you can maintain a clear structure of the runs and their relationships in your tracing system.\n"
     ]
    }
   ],
   "source": [
    "question = \"How do I trace with tracing context?\"\n",
    "ai_answer = langsmith_rag(question)\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wrap_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrap_openai/wrapOpenAI methods in Python/TypeScript allow you to wrap your OpenAI client in order to automatically log traces -- no decorator or function wrapping required! The wrapper works seamlessly with the @traceable decorator or traceable function and you can use both in the same application.\n",
    "\n",
    "You still need to set your `LANGSMITH_API_KEY` and `LANGSMITH_TRACING`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AWTT](../../images/alternative_ways_to_trace_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import wrap_openai\n",
    "# from langsmith.wrappers import wrap_openai\n",
    "import openai\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "MODEL_PROVIDER = \"openai\"\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Wrap the OpenAI Client\n",
    "openai_client = openai.Client()\n",
    "\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": RAG_SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    # TODO: We don't need to use @traceable on a nested function call anymore,\n",
    "    # wrap_openai takes care of this for us\n",
    "    return call_openai(messages)\n",
    "\n",
    "@traceable\n",
    "def call_openai(\n",
    "    messages: List[dict],\n",
    ") -> str:\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def langsmith_rag_with_wrap_openai(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not specify whether `wrap_openai` automatically traces. Therefore, I don't know the answer to your question.\n"
     ]
    }
   ],
   "source": [
    "question = \"does wrap_openai automatically trace\"\n",
    "ai_answer = langsmith_rag_with_wrap_openai(question)\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapped OpenAI client accepts all the same langsmith_extra parameters as @traceable decorated functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-CN08jA9uVnQDxiBePFJVGujLzSWWx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"The color of the sky typically appears blue during the day due to a phenomenon called Rayleigh scattering, where shorter blue wavelengths of sunlight are scattered in all directions by the gases and particles in the Earth's atmosphere. However, during sunrise and sunset, the sky can take on shades of orange, pink, and red due to the angle of the sun and the scattering of light. At night, the sky appears dark and may be dotted with stars, which can give it a black or deep navy color. Weather conditions, pollution, and other factors can also influence the color of the sky.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1759598117, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_560af6e559', usage=CompletionUsage(completion_tokens=116, prompt_tokens=13, total_tokens=129, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What color is the sky?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "openai_client.chat.completions.create(\n",
    "    model=MODEL_NAME,\n",
    "    messages=messages,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## [Advanced] RunTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another, more explicit way to log traces to LangSmith is via the RunTree API. This API allows you more control over your tracing - you can manually create runs and children runs to assemble your trace. You still need to set your `LANGSMITH_API_KEY`, but `LANGSMITH_TRACING` is not necessary for this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AWTT](../../images/alternative_ways_to_trace_4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "# I have my env variables defined in a .env file\n",
    "load_dotenv(dotenv_path=\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and set `LANGSMITH_TRACING` to false, as we are using RunTree to manually create runs in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"false\"\n",
    "\n",
    "from langsmith import utils\n",
    "utils.tracing_is_enabled() # This should return false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have rewritten our RAG application, except this time we pass a RunTree argument through our function calls, and create child runs at each layer. This gives our RunTree the same hierarchy that we were automatically able to establish with @traceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import RunTree\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "openai_client = OpenAI()\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "def retrieve_documents(parent_run: RunTree, question: str):\n",
    "    # Create a child run\n",
    "    child_run = parent_run.create_child(\n",
    "        name=\"Retrieve Documents\",\n",
    "        run_type=\"retriever\",\n",
    "        inputs={\"question\": question},\n",
    "    )\n",
    "    documents = retriever.invoke(question)\n",
    "    # Post the output of our child run\n",
    "    child_run.end(outputs={\"documents\": documents})\n",
    "    child_run.post()\n",
    "    return documents\n",
    "\n",
    "def generate_response(parent_run: RunTree, question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    rag_system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise.\n",
    "    \"\"\"\n",
    "    # Create a child run\n",
    "    child_run = parent_run.create_child(\n",
    "        name=\"Generate Response\",\n",
    "        run_type=\"chain\",\n",
    "        inputs={\"question\": question, \"documents\": documents},\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": rag_system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    openai_response = call_openai(child_run, messages)\n",
    "    # Post the output of our child run\n",
    "    child_run.end(outputs={\"openai_response\": openai_response})\n",
    "    child_run.post()\n",
    "    return openai_response\n",
    "\n",
    "def call_openai(\n",
    "    parent_run: RunTree, messages: List[dict], model: str = \"gpt-4o-mini\", temperature: float = 0.0\n",
    ") -> str:\n",
    "    # Create a child run\n",
    "    child_run = parent_run.create_child(\n",
    "        name=\"OpenAI Call\",\n",
    "        run_type=\"llm\",\n",
    "        inputs={\"messages\": messages},\n",
    "    )\n",
    "    openai_response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    # Post the output of our child run\n",
    "    child_run.end(outputs={\"openai_response\": openai_response})\n",
    "    child_run.post()\n",
    "    return openai_response\n",
    "\n",
    "def langsmith_rag(question: str):\n",
    "    # Create a root RunTree\n",
    "    root_run_tree = RunTree(\n",
    "        name=\"Chat Pipeline\",\n",
    "        run_type=\"chain\",\n",
    "        inputs={\"question\": question}\n",
    "    )\n",
    "\n",
    "    # Pass our RunTree into the nested function calls\n",
    "    documents = retrieve_documents(root_run_tree, question)\n",
    "    response = generate_response(root_run_tree, question, documents)\n",
    "    output = response.choices[0].message.content\n",
    "\n",
    "    # Post our final output\n",
    "    root_run_tree.end(outputs={\"generation\": output})\n",
    "    root_run_tree.post()\n",
    "    return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing generally refers to the process of tracking the execution of a program or system to understand its behavior, identify issues, or gather performance metrics. In software development, it can involve logging function calls, variable values, and execution paths. The goal is to provide insights into how a program operates and to facilitate debugging and optimization.\n"
     ]
    }
   ],
   "source": [
    "question = \"what is tracing?\"\n",
    "ai_answer = langsmith_rag(question)\n",
    "print(ai_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
